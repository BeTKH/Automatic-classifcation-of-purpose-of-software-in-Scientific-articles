{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017ae6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextWindow(text, bef, aft):\n",
    "    \n",
    "    def add_neighbours(*sentcs):\n",
    "        \n",
    "        # unpack list of sentcs passed\n",
    "        lis_sents = list(sentcs)\n",
    "    \n",
    "        joined_tokens = []\n",
    "\n",
    "        for i in range(len(lis_sents)):\n",
    "        \n",
    "            joined_tokens.extend(lis_sents[i].split())\n",
    "        \n",
    "            joined_sent = ' '.join(joined_tokens)\n",
    "    \n",
    "        return joined_sent\n",
    "    \n",
    "    \n",
    "    \n",
    "    #xB, yA   --- where  x,y > len(text)\n",
    "    if (bef >= len(text)-1) or (aft >= len(text)-1):\n",
    "        \n",
    "        # reset the context within paragrapgh , returns the whole paragrapgh \n",
    "        \n",
    "        bef = len(text)- 1\n",
    "        aft = len(text)- 1\n",
    "        \n",
    "        contxt_txt = []        \n",
    "        \n",
    "        for i in range(len(text)):  \n",
    "            \n",
    "            contxt_txt.append( ' '.join(text))\n",
    "\n",
    "        return contxt_txt\n",
    "        \n",
    "        \n",
    "    # 0B, OA --- no change\n",
    "    elif (bef == 0) and (aft == 0):\n",
    "        return text\n",
    "\n",
    "    # 0B, 1A --- 2 conditions  \n",
    "    elif (bef == 0) and (aft == 1):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            # 0B, 1A\n",
    "            if (i >= 0) and (i < len(text)-1):\n",
    "                contxt_txt.append( add_neighbours(text[i], text[i+1])) \n",
    "\n",
    "            # 0B, 0A\n",
    "            elif i == len(text)-1:\n",
    "                contxt_txt.append(text[i]) \n",
    "\n",
    "        return contxt_txt\n",
    "\n",
    "    #OB, 2A --- 3 conditions\n",
    "    elif (bef == 0) and (aft == 2):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            #OB, 2A\n",
    "            if (i >= 0) and (i <len(text)-2):\n",
    "                contxt_txt.append( add_neighbours(text[i], text[i+1], text[i+2]))\n",
    "\n",
    "            elif i == (len(text)-2):\n",
    "                contxt_txt.append( add_neighbours(text[i], text[i+1] ))\n",
    "\n",
    "            elif i == (len(text)-1):\n",
    "                contxt_txt.append(text[i])\n",
    "\n",
    "        return contxt_txt\n",
    "\n",
    "\n",
    "    #1B, 0A --- 2 conditions\n",
    "    elif (bef == 1) and (aft == 0):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            #0B, 0A\n",
    "            if (i == 0):\n",
    "                contxt_txt.append(text[i])\n",
    "\n",
    "            elif (i >0):\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i]))\n",
    "\n",
    "        return contxt_txt\n",
    "\n",
    "    #1B, 1A --- 3 conditions \n",
    "    elif ( bef == 1 ) and ( aft == 1):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            if i == 0:   # 0B, 1A\n",
    "                contxt_txt.append(add_neighbours (text[i], text[i+1]))\n",
    "\n",
    "            elif (i > 0) and ( i < len(text)-1):  # 1B ,1A\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1]))\n",
    "\n",
    "            elif (i == len(text)-1):  #1B, 0A\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i]))\n",
    "        return contxt_txt\n",
    "\n",
    "    #1B, 2A --- 4 conditions\n",
    "    elif (bef ==1 ) and (aft == 2):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            if i ==0:\n",
    "                contxt_txt.append(add_neighbours(text[i], text[i+1], text[i+2]))  #0B, 2A\n",
    "\n",
    "            elif (i > 0) and (i < len(text)-2):\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1],text[i+2]))     #1B, 2A\n",
    "\n",
    "            elif (i == len(text)-2):\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i],text[i+1]))               #1B, 1A\n",
    "\n",
    "            elif i == (len(text)-1):\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i]))                         #1B,0A\n",
    "        return contxt_txt\n",
    "\n",
    "    #2B, 0A   -- 3 cases \n",
    "    elif( bef ==2) and ( aft == 0):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            if i == 0:       \n",
    "                contxt_txt.append(text[i])         #0B, 0A\n",
    "            elif i == 1:\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i]))            #1B, 0A\n",
    "            elif i > 1:\n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i]))  #2B, 0A\n",
    "        return contxt_txt\n",
    "\n",
    "    #2B, 1A -- 3 cases\n",
    "    elif ( bef == 2 ) and (aft == 1):\n",
    "        contxt_txt = []\n",
    "        for i in range(len(text)):\n",
    "            if i ==0: \n",
    "                contxt_txt.append(add_neighbours(text[i], text[i+1]) )                     #0B, 1A\n",
    "\n",
    "            elif i ==1:\n",
    "                contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1]) )          #1B, 1A\n",
    "\n",
    "            elif (i > 1) and (i < len(text)-1):\n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1]))  # 2B, 1A\n",
    "\n",
    "            elif i == len(text)-1:\n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-2], text[i]))           #2B, 0A\n",
    "\n",
    "        return contxt_txt\n",
    "\n",
    "    #2B, 2A --- 5 conditions\n",
    "    elif (bef == 2) and (aft == 2):        \n",
    "        contxt_txt = []        \n",
    "        for i in range(len(text)):    \n",
    "            \n",
    "            #print(f' there are {len(text)} sentences in {text}')\n",
    "\n",
    "            if i == 0:    # 0B, 2A\n",
    "                contxt_txt.append(add_neighbours(text[i] , text[i+1] , text[i+2]))  \n",
    "\n",
    "            elif i == 1:  # 1B, 2A\n",
    "                contxt_txt.append(add_neighbours(text[i-1] , text[i] , text[i+1] , text[i+2]))\n",
    "\n",
    "            elif (i >=1) and (i < len(text)-2):   # 2B , 2A \n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1], text[i+2]))\n",
    "\n",
    "            elif (i == len(text)-2):             #2B, 1A\n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1]))\n",
    "\n",
    "            elif i == len(text)-1:                #2B, 0A  \n",
    "                contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i]))\n",
    "                \n",
    "        return contxt_txt\n",
    "                \n",
    "    #3B, 3A --- 7 conditions\n",
    "    elif (bef == 3) and (aft == 3):\n",
    "        \n",
    "        contxt_txt = []        \n",
    "        for i in range(len(text)):\n",
    "            \n",
    "            if i == 0:  #0B, 3A\n",
    "                contxt_txt.append(add_neighbours(text[i] , text[i+1] , text[i+2] + text[i+3] ))\n",
    "            \n",
    "            elif i ==1: #1B, 3A\n",
    "                contxt_txt.append(add_neighbours(text[i-1] + text[i] , text[i+1] , text[i+2] + text[i+3] ))\n",
    "            \n",
    "            elif i ==2: #2B, 3A\n",
    "                contxt_txt.append(add_neighbours(text[i-2] + text[i-1] + text[i] , text[i+1] , text[i+2] + text[i+3] ))\n",
    "            \n",
    "            elif (i >=3) and (i < len(text)-3): #3B, 3A\n",
    "                contxt_txt.append(add_neighbours(text[i-3]+text[i-2] + text[i-1] + text[i] , text[i+1] , text[i+2] + text[i+3] ))\n",
    "            \n",
    "            elif (i == len(text)-3): #3B, 2A\n",
    "                contxt_txt.append(add_neighbours(text[i-3]+text[i-2] + text[i-1] + text[i] , text[i+1] , text[i+2] ))\n",
    "            \n",
    "            elif (i == len(text)-2): #3B, 1A\n",
    "                contxt_txt.append(add_neighbours(text[i-3]+text[i-2] + text[i-1] + text[i] , text[i+1]))\n",
    "            \n",
    "            elif (i == len(text)-1): #3B, 0A\n",
    "                contxt_txt.append(add_neighbours(text[i-3]+text[i-2] + text[i-1] + text[i] ))\n",
    "                \n",
    "        return contxt_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160b96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = []\n",
    "#with path.open(mode='r') as in_f:\n",
    "#    for line in in_f:\n",
    "#        clean_line = line.rstrip()\n",
    "#        if clean_line:\n",
    "#            text.append(clean_line)\n",
    "#        elif read_empty:\n",
    "#            text.append([])\n",
    "\n",
    "#return contextWindow(text, bef, aft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73409161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Text(path):\n",
    "    \n",
    "    with path.open(mode='r') as in_f:\n",
    "        \n",
    "        cont = in_f.read()\n",
    "        \n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36d77a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The captured rodents were taxonomically identified to strain level according to criteria developed by Chen and Qiu [20] .',\n",
       " 'Rodent density was calculated as a proportion ( total number of captured rodents / total number of valid mouse traps ) .',\n",
       " 'An invalid mouse trap was defined as either a missing trap or non - rodent triggered trap .']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_to_file = Path('/home/beck/Desktop/articlenizer/data/PLoS_methods_bio/PMC4507865.data.txt')\n",
    "\n",
    "# read the text \n",
    "txt_bio = read_Text(path_to_file)\n",
    "\n",
    "# list of paraggrapghs in the txt\n",
    "par_list = txt_bio.split('\\n\\n')\n",
    "\n",
    "# list of sentences in the 1st paragrapgh \n",
    "\n",
    "snt_pa_3 = par_list[2].split('\\n')\n",
    "\n",
    "snt_pa_3[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e8ab23f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The captured rodents were taxonomically identified to strain level according to criteria developed by Chen and Qiu [20] . Rodent density was calculated as a proportion ( total number of captured rodents / total number of valid mouse traps ) . An invalid mouse trap was defined as either a missing trap or non - rodent triggered trap .'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the whole paragrapgh as a context\n",
    "\n",
    "#contx_whole_par = contextWindow(snt_pa_1, len(snt_pa_1), len(snt_pa_1))\n",
    "\n",
    "contx_22  = contextWindow(snt_pa_3, 2, 2)\n",
    "contx_22[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3701e13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Study sites and data collection : Study sites and monthly meteorological data collection have previously been described [19] . The sites were composed of 13 districts : Banan , Changshou , Fengdu , Fengjie , Fuling , Kaixian , Wanzhou , Shizhu , Wulong , Wushan , Yubei , Yunyang and Zhongxian . These districts are located along the Yangtze River ( Fig 1 ) .', 'Study sites and data collection : Study sites and monthly meteorological data collection have previously been described [19] . The sites were composed of 13 districts : Banan , Changshou , Fengdu , Fengjie , Fuling , Kaixian , Wanzhou , Shizhu , Wulong , Wushan , Yubei , Yunyang and Zhongxian . These districts are located along the Yangtze River ( Fig 1 ) .', 'Study sites and data collection : Study sites and monthly meteorological data collection have previously been described [19] . The sites were composed of 13 districts : Banan , Changshou , Fengdu , Fengjie , Fuling , Kaixian , Wanzhou , Shizhu , Wulong , Wushan , Yubei , Yunyang and Zhongxian . These districts are located along the Yangtze River ( Fig 1 ) .']\n"
     ]
    }
   ],
   "source": [
    "for par_ in par_list[:1]:\n",
    "    \n",
    "    # list of sentences in the paragrapgh\n",
    "    snt_lst_ = par_.split('\\n')\n",
    "    \n",
    "    # number of sentences i the paragrapgh\n",
    "    \n",
    "    cntx = contextWindow(snt_lst_, 2, 2)\n",
    "        \n",
    "    print(cntx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "contx_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_bio_par_list[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571be74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
