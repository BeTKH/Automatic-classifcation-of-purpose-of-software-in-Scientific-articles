{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73409161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_text_file(path, bef, aft, read_empty=False):\n",
    "    \n",
    "    def add_neighbours(*sentcs):\n",
    "        \n",
    "        # unpack list of sentcs passed\n",
    "        lis_sents = list(sentcs)\n",
    "    \n",
    "        joined_tokens = []\n",
    "\n",
    "        for i in range(len(lis_sents)):\n",
    "        \n",
    "            joined_tokens.extend(lis_sents[i].split())\n",
    "        \n",
    "            joined_sent = ' '.join(joined_tokens)\n",
    "    \n",
    "        return joined_sent\n",
    "    \n",
    "    def contextWindow(text, bef, aft):\n",
    "        # 0B, OA --- no change\n",
    "        if (bef == 0) and (aft == 0):\n",
    "            return text\n",
    "        \n",
    "        # 0B, 1A --- 2 conditions  \n",
    "        elif (bef == 0) and (aft == 1):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                # 0B, 1A\n",
    "                if (i >= 0) and (i < len(text)-1):\n",
    "                    contxt_txt.append( add_neighbours(text[i], text[i+1])) \n",
    "                    \n",
    "                # 0B, 0A\n",
    "                elif i == len(text)-1:\n",
    "                    contxt_txt.append(text[i]) \n",
    "                    \n",
    "            return contxt_txt\n",
    "            \n",
    "        #OB, 2A --- 3 conditions\n",
    "        elif (bef == 0) and (aft == 2):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                #OB, 2A\n",
    "                if (i >= 0) and (i <len(text)-2):\n",
    "                    contxt_txt.append( add_neighbours(text[i], text[i+1], text[i+2]))\n",
    "                    \n",
    "                elif i == (len(text)-2):\n",
    "                    contxt_txt.append( add_neighbours(text[i], text[i+1] ))\n",
    "                    \n",
    "                elif i == (len(text)-1):\n",
    "                    contxt_txt.append(text[i])\n",
    "                    \n",
    "            return contxt_txt\n",
    "        \n",
    "        \n",
    "        #1B, 0A --- 2 conditions\n",
    "        elif (bef == 1) and (aft == 0):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                #0B, 0A\n",
    "                if (i == 0):\n",
    "                    contxt_txt.append(text[i])\n",
    "                    \n",
    "                elif (i >0):\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i]))\n",
    "                    \n",
    "            return contxt_txt\n",
    "    \n",
    "        #1B, 1A --- 3 conditions \n",
    "        elif ( bef == 1 ) and ( aft == 1):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                if i == 0:   # 0B, 1A\n",
    "                    contxt_txt.append(add_neighbours (text[i], text[i+1]))\n",
    "                    \n",
    "                elif (i > 0) and ( i < len(text)-1):  # 1B ,1A\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1]))\n",
    "                    \n",
    "                elif (i == len(text)-1):  #1B, 0A\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i]))\n",
    "            return contxt_txt\n",
    "    \n",
    "        #1B, 2A --- 4 conditions\n",
    "        elif (bef ==1 ) and (aft == 2):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                if i ==0:\n",
    "                    contxt_txt.append(add_neighbours(text[i], text[i+1], text[i+2]))  #0B, 2A\n",
    "                    \n",
    "                elif (i > 0) and (i < len(text)-2):\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1],text[i+2]))     #1B, 2A\n",
    "                    \n",
    "                elif (i == len(text)-2):\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i],text[i+1]))               #1B, 1A\n",
    "                    \n",
    "                elif i == (len(text)-1):\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i]))                         #1B,0A\n",
    "            return contxt_txt\n",
    "    \n",
    "        #2B, 0A   -- 3 cases \n",
    "        elif( bef ==2) and ( aft == 0):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                if i == 0:       \n",
    "                    contxt_txt.append(text[i])         #0B, 0A\n",
    "                elif i == 1:\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i]))            #1B, 0A\n",
    "                elif i > 1:\n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i]))  #2B, 0A\n",
    "            return contxt_txt\n",
    "    \n",
    "        #2B, 1A -- 3 cases\n",
    "        elif ( bef == 2 ) and (aft == 1):\n",
    "            contxt_txt = []\n",
    "            for i in range(len(text)):\n",
    "                if i ==0: \n",
    "                    contxt_txt.append(add_neighbours(text[i], text[i+1]) )                     #0B, 1A\n",
    "                    \n",
    "                elif i ==1:\n",
    "                    contxt_txt.append(add_neighbours(text[i-1], text[i], text[i+1]) )          #1B, 1A\n",
    "                    \n",
    "                elif (i > 1) and (i < len(text)-1):\n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1]))  # 2B, 1A\n",
    "                    \n",
    "                elif i == len(text)-1:\n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-2], text[i]))           #2B, 0A\n",
    "                    \n",
    "            return contxt_txt\n",
    "            \n",
    "        #2B, 2A --- 5 conditions\n",
    "        elif (bef == 2) and (aft == 2):        \n",
    "            contxt_txt = []        \n",
    "            for i in range(len(text)):    \n",
    "        \n",
    "                if i == 0:    # 0B, 2A\n",
    "                    contxt_txt.append(add_neighbours(text[i] , text[i+1] , text[i+2]))  \n",
    "                    \n",
    "                elif i == 1:  # 1B, 2A\n",
    "                    contxt_txt.append(add_neighbours(text[i-1] , text[i] , text[i+1] , text[i+2]))\n",
    "                    \n",
    "                elif (i >=2) and (i < len(text)-2):   # 2B , 2A \n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1], text[i+2]))\n",
    "                    \n",
    "                elif (i == len(text)-2):             #2B, 1A\n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i], text[i+1]))\n",
    "                    \n",
    "                elif i == len(text)-1:                #2B, 0A  \n",
    "                    contxt_txt.append(add_neighbours(text[i-2], text[i-1], text[i]))      \n",
    "                    \n",
    "            return contxt_txt\n",
    "    \n",
    "    text = []\n",
    "    with path.open(mode='r') as in_f:\n",
    "        for line in in_f:\n",
    "            clean_line = line.rstrip()\n",
    "            if clean_line:\n",
    "                text.append(clean_line)\n",
    "            elif read_empty:\n",
    "                text.append([])\n",
    "                \n",
    "    return contextWindow(text, bef, aft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d77a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dax/PMC4507865.data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m path_to_label \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdax/PMC4507865.labels.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m path_to_original_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdax/PMC4507865.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m txt_bio \u001b[38;5;241m=\u001b[39m \u001b[43m_read_text_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m lbl \u001b[38;5;241m=\u001b[39m _read_text_file(path_to_label, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m txt_o \u001b[38;5;241m=\u001b[39m _read_text_file(path_to_original_file, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m_read_text_file\u001b[0;34m(path, bef, aft, read_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m contxt_txt\n\u001b[1;32m    150\u001b[0m text \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m in_f:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m in_f:\n\u001b[1;32m    153\u001b[0m         clean_line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mrstrip()\n",
      "File \u001b[0;32m/usr/lib/python3.8/pathlib.py:1222\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_closed()\n\u001b[0;32m-> 1222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m               \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/pathlib.py:1078\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dax/PMC4507865.data.txt'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path_to_file = Path('dax/PMC4507865.data.txt')\n",
    "path_to_label = Path('dax/PMC4507865.labels.txt')\n",
    "path_to_original_file = Path('dax/PMC4507865.txt')\n",
    "\n",
    "txt_bio = _read_text_file(path_to_file,  0, 0)\n",
    "lbl = _read_text_file(path_to_label, 0, 0)\n",
    "txt_o = _read_text_file(path_to_original_file, 0, 0)\n",
    "\n",
    "num_pars = len(txt_o)\n",
    "num_sents_par_1 = len(txt_o[0].split())\n",
    "\n",
    "print(f\"number of paragraphs: {num_pars}\")\n",
    "print(f\"number of sentences in paragrapgh_1: {num_sents_par_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9d807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Study sites and data collection: Study sites and monthly meteorological data collection have previously been described [19].The sites were composed of 13 districts: Banan, Changshou, Fengdu, Fengjie, Fuling, Kaixian, Wanzhou, Shizhu, Wulong, Wushan, Yubei, Yunyang and Zhongxian. These districts are located along the Yangtze River (Fig 1).'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragrapgh_1 = txt_o[0]\n",
    "paragrapgh_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3701e13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study\n"
     ]
    }
   ],
   "source": [
    "bio_paragrapgh_dict = {}   \n",
    "    \n",
    "# number of paragrapghs is same as length of original text\n",
    "num_pars = len(txt_o)\n",
    "\n",
    "for i in range(num_pars):\n",
    "    \n",
    "    # list of list down all tokens in the current i-th paragrapgh\n",
    "    lsl_tkns_par = sents_in_paragrapgh(txt_o[i])\n",
    "    \n",
    "    #print(lsl_tkns_par)\n",
    "    \n",
    "    # check each sentence in bio list if it is in the current paragrapgh\n",
    "    bio_list_in_par = []\n",
    "    \n",
    "    for bio_snt in txt_bio:\n",
    "        \n",
    "        bio_tkns = bio_snt.split()\n",
    "        \n",
    "        for bio_tkn in bio_tkns:\n",
    "            \n",
    "            print(bio_tkn)\n",
    "            \n",
    "            break\n",
    "            \n",
    "        break\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acac3436",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m lst_of_sents_in_current_par \u001b[38;5;241m=\u001b[39m sents_in_paragrapgh(txt_o[i])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# list of tokens in the current paragrapgh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m paragrapgh_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlst_of_sents_in_current_par\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# check each sentence in bio list if it is in the current paragrapgh\u001b[39;00m\n\u001b[1;32m     10\u001b[0m bio_list_in_par \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "for i in range(num_pars):\n",
    "\n",
    "    # list down all sentences in the current i-th paragrapgh, tokenized and normalized\n",
    "    lst_of_sents_in_current_par = sents_in_paragrapgh(txt_o[i])\n",
    "    \n",
    "    # list of tokens in the current paragrapgh\n",
    "    paragrapgh_tokens = ' '.join(lst_of_sents_in_current_par).split()\n",
    "\n",
    "    # check each sentence in bio list if it is in the current paragrapgh\n",
    "    bio_list_in_par = []\n",
    "\n",
    "    for bio_snt in txt_bio:\n",
    "        \n",
    "        bio_sent_tokens = bio_snt.split()\n",
    "        \n",
    "        print(bio_sent_tokens, len(bio_sent_tokens))\n",
    "        break\n",
    "\n",
    "        # if bio_sentence is present in lst_of_sents_in_current_par , append to bio_list_in_par\n",
    "        if bio_snt in lst_of_sents_in_current_par:\n",
    "            \n",
    "            bio_list_in_par.append(bio_snt)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    break\n",
    "\n",
    "    bio_paragrapgh_dict[i] = bio_list_in_par"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
