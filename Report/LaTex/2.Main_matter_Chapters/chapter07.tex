\chapter{Conclusion and Future work}
\label{ch:chapter07}
 
%
% Section:7 - Intro
%

\section{Summary }
\label{sec:chapter06:summary}

Evaluation of \ac{BERT} models used in this thesis, \ac{Sci-BERT} and \ac{Bio-BERT}, revealed important observations. Firstly, the analysis of Sci-BERT \emph{software-purpose} classification indicates that composition of training dataset has significant impact on the software purpose classification. Overall, when Sci-BERT classifier model is trained by including parts of the SoMeSci dataset that do not have software purpose annotations, software purpose classification performance is deteriorated. However, classification performance for software purpose is increased when the Sci-BERT model is trained with parts of \ac{SoMeSci} dataset that have software-purpose annotations. This result clearly indicates, including unlabeled dataset in the training data degrades software-purpose classification performance.  \\

Secondly, it has been observed that various levels of context can affect software purpose classification performance. Training of a classifier model based on neighboring sentences, in a scientific articles of SoMeSci dataset, has been seen to improve software purpose classification performance. Typically, a context information with two sentences at the left-side (2,0) of a given sentence appears to give more important clue for the \ac{Sci-BERT} \emph{software-purpose} classifier. However, unbounded context information such as the whole paragraph or a context not limited within a paragraph did not provide better classification performance compared to context information limited to only two sentences from the left-side(2,0) as shown on the figure 6.4. \\


Thirdly, evaluation of the Sci-BERT model's performance by removing the intermediate modules of \emph{software-type} and \emph{mention-type} classifiers from the 4-cascade classifier shown on fig. 5.6, produced a slightly better performance for \emph{software purpose} classification.  This indicates that flawed classifications, from the middle classifier modules of the 4-cascade, potentially impact \emph{software-purpose} classifier's performance which lies at the end of cascade of classifier modules. \\

Further more, it was observed that training other variants of BERT model such as Bio-BERT-base and Bio-BERT-large model results in a different software-purpose classification performance. The Bio-BERT-large model has slightly better performance compared with Sci-BERT but it is too slow for training. On the other hand Bio-BERT-small trains fast but its software purpose classification performance is lower than Sci-BERT. \\


Generally, it is also observed that \emph{software purpose} classification performance is greater for software purposes with larger number of class labels such as \emph{analysis} compared to other software usage purposes like \emph{stimulation or simulation} which has smaller number of class labels.   

 

\section{Conclusion}
\label{sec:chapter07:Conclusion}

The role of software in the modern scientific research is paramount. However, the use of software in a research entailed problems such as research result reliability and reproducibility. Automatically extracted information about software, such as software-purpose, can help to mitigate these problems by identifying a set of related software tools in terms of purpose of usage. Results from related software tools can be compared to cross-validate and ensure reliability of research outcomes. \\


Automatic classification of software-purposes have been possible with availability of labeled datasets and state-of-the-art deep learning models, such as \ac{BERT}. BERT models are efficient for software purpose classification because of their capability for transfer-learning and does not require a lot of training data, unlike \ac{LSTM} networks. \\

Results of software-purpose classification indicates reasonable classification performance despite limited availability of labeled datasets of \ac{SoMeSci} and unbalanced class labels for software purposes. Particularly, the classifier model performed significantly better for software purposes whith larger number of class labels such as Analysis. \\


The analysis of the \ac{SoMeSci} dataset also, revealed most scientists use software to carry out specific tasks in a research, fewer software-purposes, as shown on the figure 4.12. This concurs with the fact that most scientists develop software for their scientific work. \\ 


\section{Limitations and Future Work}
\label{sec:chapter07:futurework}

In this thesis, for automatic classification of software-purposes only part of the \ac{SoMeSci} dataset was annotated because of time constraint. Because of this for most software-purposes, such as simulation and stimulation, there were no enough examples for training of classifier model. \\

To increase software purpose classification performance, in the future, the remaining part of SoMeSci dataset can also be annotated to increase software purpose classification performance. In addition, the SoMeSci corpus size could also be increased slightly to increase software-purpose classification. Further more, annotation of software-usage purposes can also be done by domain experts to increase correct classification of software-purpose classification. \\

Based on extracted information about software purposes, a set of similar software tools can also be identified from scientific articles to cross-validate results of a research using software tools that are used for the same purpose. Further more, semantic browsing of scientific articles based on use of software for the same purpose can also be implemented. 




